<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>dispar.at Blog</title>
  
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="http://dispar.at/blog/"/>
  <updated>2017-07-15T10:06:39.718Z</updated>
  <id>http://dispar.at/blog/</id>
  
  <author>
    <name>Stephan Hesse</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Design of scheduling and rate-adaptation algorithms for adaptive HTTP streaming</title>
    <link href="http://dispar.at/blog/2017/07/08/spie-article-2013/"/>
    <id>http://dispar.at/blog/2017/07/08/spie-article-2013/</id>
    <published>2017-07-08T14:54:33.000Z</published>
    <updated>2017-07-15T10:06:39.718Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hey-there-I-have-done-some-science"><a href="#Hey-there-I-have-done-some-science" class="headerlink" title="Hey there, I have done some science"></a>Hey there, I have done some science</h1><p>In 2013 I published an article as part of the SPIE conference proceedings in San Diego 2013. The article can be found in the <a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1744318" target="_blank" rel="external">SPIE digital library</a>. The original document can also be found <a href="https://drive.google.com/open?id=0Bytk0Mk6whyiR2R5ZWp6dkVzS0k" target="_blank" rel="external">here</a>.</p>
<p>This would not have happened without the very valuable help of <a href="http://reznik.org/" target="_blank" rel="external">Yuri Reznik</a>. Here, I’d like to thank him a lot for this, once again! </p>
<p>Equally, I’d like to thank again my former thesis supervisors and later Fraunhofer HHI colleagues Yago Sanchez, Thomas Schierl, Cornelius Hellge and Prof. Thomas Wiegand. My master thesis written about the same subject was substantial to the contents of this article.</p>
<p>Now that I have this blog (5 years later! :D), I want to give a quick overview to the contents of this article.</p>
<h1 id="What-is-adaptive-streaming"><a href="#What-is-adaptive-streaming" class="headerlink" title="What is adaptive streaming?"></a>What is adaptive streaming?</h1><p>Adaptive streaming over HTTP is a general concept to allow live or finite on-demand audio/video content streams to be transmitted through web infrastructure through channels with varying bandwidth/latency towards a wide range of device types (resolutions and decoding capabilities) - thus the term “adaptive”. The receiver clients’ streaming engine can potentially select and switch across various qualities/bitrates/resolutions or audio channel numbers and codecs, depending on the given conditions on the receiver side.</p>
<h1 id="How-to-make-that-work"><a href="#How-to-make-that-work" class="headerlink" title="How to make that work?"></a>How to make that work?</h1><p>What defines an adaptive streaming receiver client, is the technique used to schedule HTTP requests that will contain segments of the stream it needs to display. In order to have a uninterrupted streaming session, the streaming engine needs to keep the playback buffers sufficiently filled at all times. That requires to select appropriate stream(s) bitrate(s) that will be transmittable through the channel we have at disposition.</p>
<p>When having a live stream, the potential buffer size one may have is limited, therefore “pre-buffering” all of the stream in awesome quality is not a solution. Sorry :) Also, one usually wants to watch a stream <em>asap</em>. Even more, the buffer size in memory is limited on many devices (especially web browsers) to very tangible amounts. This becomes even more a problem as our streams become heavier with HD and 4K resolutions.</p>
<p>Let’s consider that all streams can be seen therefore as live, and that the maximum buffer size one may have can only be up to a 120 seconds or less (in real live broadcast cases we usually talk of not more than 30 seconds). This assumption should help us to understand the trickyness of the problem :)</p>
<h1 id="Channels-on-the-internet-are-chaos"><a href="#Channels-on-the-internet-are-chaos" class="headerlink" title="Channels on the internet are chaos"></a>Channels on the internet are chaos</h1><p>A client does not know per-se anything about the channel capabilites. Plus, due to the nature of the internet, channels are unpredictable in the first place. Therefore we have protocols like <a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol" target="_blank" rel="external">TCP</a> which have clients/servers/routers/switches create a self-regulated distributed system in which we try to balance out the overall traffic on the network. A client can only make an educated guess of the <em>virtual</em> channel properties it has at disposition - what it sees is really an aggregation and chaining of may physical channel models, modulated by the unpredictable behavior of other peers with which it is sharing the network.</p>
<p>Therefore an adaptive streaming client needs to make an estimation to approximate the correct bitrate to select, eventually based on previously recorded statistics within the same streaming session, i.e using the same connection and thus exposed to similar transmission conditions.</p>
<h1 id="A-classic-signals-and-systems-approach"><a href="#A-classic-signals-and-systems-approach" class="headerlink" title="A classic signals and systems approach"></a>A classic signals and systems approach</h1><p>The approach of this article is to use a typical estimator approach of signals and systems theory: The exponential smoothing filter.</p>
<p>We are simply feeding the filter with bandwidth measurement samples. There is a whole lot assumptions and approximations about the properties of the stream and its segments to be made in order for this approach to be valid. I’ll spare the math here :)</p>
<p>What comes out of the filter may be a really good guess for what bitrate to select next in your streaming session. In terms of statistics this kind of filter really is something that gives you an average of previously input values. The nice thing about it is that values are all weighted by their “age”, in an exponential manner. Physical systems often have exponential laws in them, therefore it may come in handy to predict a chaotic thing like the internet with something exponential?</p>
<h1 id="Taking-experiences-into-account"><a href="#Taking-experiences-into-account" class="headerlink" title="Taking experiences into account"></a>Taking experiences into account</h1><p>What really is helpful here is that one can take old “experiences” into account, but they will eventually fade away completely, and newer inputs will always have a much bigger weight. Which is important when you need to “adapt”. Compare this to an averaging weight that may be linear, or even flat, you may run into serious problems over time as new inputs may become insignifcant compared to the weight of thousands of previously recorded samples. This is why usually one talks of a “moving” average. It only takes into account so many previous samples and “forgets” about the older stuff. That is also a valid approach, it just has different parameters to optimize on.</p>
<p>An exponential smoothing filter has <em>one</em> parameter, the so-called alpha. It basically tells you how much smoothing the output value should get. A lot of smoothing means that little spikes wont be visible, on the other hand the filter will be slow to react on step increments of the input signal - it is “slow”. Little smoothing will make the filter “fast”; on the other hand you may get “noise” on the output which you may not want in form of little spikes or statistical outliers.</p>
<h1 id="The-trade-offs"><a href="#The-trade-offs" class="headerlink" title="The trade-offs"></a>The trade-offs</h1><p>You get the idea: It’s a trade-off, there is nothing like the perfect alpha for all cases. It’s all about what you want to bet on. Fast averaging will give you a very reactive behavior towards changes, but you may react too quickly, take a spike for general improvement of conditions, switch up your quality and … <em>BAM</em>. Buffer under-run. Too aggressive. On the other hand, a slow filter may be “safe”, but it may lead to select a bitrate much lower that what the conditions would actually allow for.</p>
<p>What the article suggests is to use a smoothing parameter depending on the buffer size we are aiming at. When using a short buffer, or when the buffer has not built up much yet, we should have a slower smoothing alpha. When using a large buffer, we should apply more smoothing. Does that make sense? Again, this is one solution with it’s pros and cons. We said that a fast alpha is less safe, so why is it better with a short buffer, shouldn’t we be more “conservative” there. It depends. A fast filter will also be fast for switching down, which is something very important when your buffer is short. When you have a long buffer, you don’t need to react to quickly on a little down-ward spike. There is no way to react quickly to negative inputs, and at the same time have optimimum quality. What this optimizes for is quick reaction when we potentially are at risk of a buffer under-run, while optimizing for quality stability once we are not at risk anymore.</p>
<p>The problem with is that one may over-estimate quickly when in the “fast” mode, at times where buffer is short. We can avoid that by having the adaptation engine have a switch-up threshold in this specific state. In that way, we can take advantage of the fast “emergency” switch-down capabilities, while not going at risk to under-run from an over-aggressive switch-up.</p>
<p>This may have the quality generally be lower than it “could” in the buffer build-up phase that may occur at the beginning of a streaming session. </p>
<h1 id="Similar-approaches-and-existing-implementations"><a href="#Similar-approaches-and-existing-implementations" class="headerlink" title="Similar approaches and existing implementations"></a>Similar approaches and existing implementations</h1><p>The whole approach has also been discussed in other litterature, there are a whole lot of articles with similar approaches. Also implementations around that use these similar approaches. One of them is the Shaka Player project.</p>
<p>Shaka implements an exponentially weighted moving average. It is a something a little different from the simple smoothing filter we use:  <a href="https://github.com/google/shaka-player/blob/af252c94e73344a4a279760a85e8c14187d87268/lib/abr/ewma.js" target="_blank" rel="external">https://github.com/google/shaka-player/blob/af252c94e73344a4a279760a85e8c14187d87268/lib/abr/ewma.js</a></p>
<p>Then the bandwidth estimator it uses simply takes the output of two of these filters, one slow, one fast and uses the “worst” estimation: <a href="https://github.com/google/shaka-player/blob/af252c94e73344a4a279760a85e8c14187d87268/lib/abr/ewma_bandwidth_estimator.js" target="_blank" rel="external">https://github.com/google/shaka-player/blob/af252c94e73344a4a279760a85e8c14187d87268/lib/abr/ewma_bandwidth_estimator.js</a></p>
<p>Very similarly, another adaptive streaming library, Videojs-contrib-HLS, uses the same approach as well: <a href="https://github.com/videojs/videojs-contrib-hls/blob/8a229d3364db63c9e6f87f6c546f7f1e428e2560/src/playlist-selectors.js#L262" target="_blank" rel="external">https://github.com/videojs/videojs-contrib-hls/blob/8a229d3364db63c9e6f87f6c546f7f1e428e2560/src/playlist-selectors.js#L262</a> </p>
<h1 id="Different-approaches-based-on-buffer-state"><a href="#Different-approaches-based-on-buffer-state" class="headerlink" title="Different approaches based on buffer state"></a>Different approaches based on buffer state</h1><p>In our approach, we are talking a lot about sampling the transmission rate, and parameterizing the estimator with the buffer state.</p>
<p>The probably much more precise and developped approach of the so-called BOLA algorithm samples the buffer state.</p>
<p>It is a different approach that has proven to work very well:</p>
<p><a href="https://arxiv.org/pdf/1601.06748.pdf" target="_blank" rel="external">BOLA: Near-Optimal Bitrate Adaptation for Online Videos”<br>(Kevin Spiteri1∗, Rahul Urgaonkar 2†, Ramesh K. Sitaraman1)</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hey-there-I-have-done-some-science&quot;&gt;&lt;a href=&quot;#Hey-there-I-have-done-some-science&quot; class=&quot;headerlink&quot; title=&quot;Hey there, I have done s
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>XHR-shaper: A network conditioner that throtlles XMLHttpRequest (that runs in the browser)</title>
    <link href="http://dispar.at/blog/2017/06/09/xhr-shaper/"/>
    <id>http://dispar.at/blog/2017/06/09/xhr-shaper/</id>
    <published>2017-06-09T18:56:01.000Z</published>
    <updated>2017-07-15T09:54:20.244Z</updated>
    
    <content type="html"><![CDATA[<h1 id="How-to-emulate-bandwidth-conditons-in-the-browser"><a href="#How-to-emulate-bandwidth-conditons-in-the-browser" class="headerlink" title="How to emulate bandwidth conditons in the browser?"></a>How to emulate bandwidth conditons in the browser?</h1><p>In the past two years I have been working a lot with JavaScript-based adaptive streaming engines. Sometime in 2016 it occured to me: there is actually a way we would be able to throttle the network traffic of the browser, from within the browser (if you are not into the topic, I’ll explain why that is a big deal to me further below). That idea was what led me to build <strong>XHR-shaper</strong> in the end.</p>
<h1 id="What-is-XHR-Shaper"><a href="#What-is-XHR-Shaper" class="headerlink" title="What is XHR-Shaper?"></a>What is XHR-Shaper?</h1><p>It’s a JavaScript module that hooks into the standard XMLHttpRequest (that is what browser-code uses to make HTTP requests). To do that, it sits in between the actual request and the standard application API which it mimics effectively - then it shapes the behavior of the state and events in such way that emulates a certain bandwidth and latency. That’s it.</p>
<p>You can try it out here: <a href="https://tchakabam.github.io/xhr-shaper/" target="_blank" rel="external">https://tchakabam.github.io/xhr-shaper/</a></p>
<p>And here is the project repository: <a href="https://github.com/tchakabam/xhr-shaper" target="_blank" rel="external">https://github.com/tchakabam/xhr-shaper</a></p>
<p>So for example with that installed one can say:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">// all requests will be limited to 64kbps and take at least 5000 ms</div><div class="line">XMLHttpRequest.Shaper.maxBandwidth = 64;</div><div class="line">XMLHttpRequest.Shaper.minLatency = 3000;</div></pre></td></tr></table></figure>
<p>And then all requests in that browser window will be really pretty slow.</p>
<p>The cool thing about that is, you can just set it up on any page or app, and then just test/play with various network conditions, without needing to actually let the app or the test-suite know about it.</p>
<p>When you want to integrate automated tests in browsers with it, it’s easy as saying hello. </p>
<p>You can also limit it to one specific request by applying it to the specific XHR instance, but that will of course have you make your application of it:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">// Set your minimum desired latency</div><div class="line">xhr.shaper.minLatency = 1000;</div><div class="line"></div><div class="line">// Set your maximum desired bandwidth</div><div class="line">xhr.shaper.maxBandwidth = 512;</div></pre></td></tr></table></figure>
<p>Here you can see a screenshot of the demo page (included in the project), where we see traces from three requests, at 500, 1000, 2000 and 10000kbps respectively. The demo page allows you to test downloading a chunk of data from a CDN (which is part of a popular test stream) - you can set max bandwidth and min latency to see how it affects the download - and traces the result in a graph.</p>
<p><img id="xhr-shaper-demo" src="/blog/images/xhr-shaper-demo.png" href="/blog/images/xhr-shaper-demo.png"></p>
<p>And finally (to close the gap to all other tech blog articles), YES you can find (and install) this via npm:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install xhr-shaper</div></pre></td></tr></table></figure>
<h1 id="What-the-heck-do-you-need-it-for"><a href="#What-the-heck-do-you-need-it-for" class="headerlink" title="What the heck do you need it for?"></a>What the heck do you need it for?</h1><p>As long as I have been working with adaptive video streaming, we had to do network emulation to test what we were doing. That means that we are emulating certain conditions of the network, like bandwidth limitation and latency for example. Hence why the tools that are doing that are called “Network conditioner”.</p>
<p>There are basically two ways to do it: via the client or server system on the IP network layer, or via specific throtlling of responses on the application layer, which can also be done on client and server.</p>
<p>When you want to setup automated testing with it usually is a hassle. But I have been through it :) The problem is that most of the time you’ll want to use tools that run on the client system, since your server is usually a static CDN when you work with media streaming (so no throttling applicable there..). So when you want to test that your adaptation algorithms run correctly, you need drive that system-wide tool at the same time - that is feasible when your test-suite actually runs on the command-line. When you want to run such tests with a browser - well that’s when things might get really tricky. In that case you may want to proxy all of your media-requests via a local proxy that does the traffic throttling - the browser can then control the throttling behavior via some controller endpoint of it. But all that seems really a bit of a hassle no?</p>
<h1 id="How-does-XHR-shaper-work-exactly"><a href="#How-does-XHR-shaper-work-exactly" class="headerlink" title="How does XHR-shaper work exactly?"></a>How does XHR-shaper work exactly?</h1><p>It’s really pretty simple. First we are over-writing the XHR in the <code>window</code> object with our own implementation, called <code>XHRProxy</code>. It really does nothing except proxying all the functions, properties and constructor to an internal “real” XHR object (we keep a ref to that constructor before we overwrite). So it works a bit like what developers in the browser-world call <code>shim</code> or <code>polyfill</code>, but the other way around :) Or the same. Just that in the end to do the download it needs to use the native already existing component.</p>
<p>Anyway. Then we are extending that proxy object at construction with some hooks, that will basically catch all of the event listeners that would usually attach directly to the native object. Also, we are masking parts of the XHR state with our stuff, so <code>response</code>, <code>readyState</code>, <code>status</code>, etc ….</p>
<p>Now as the request happens, we are progressively triggering events and setting the state in the shape of the given emulation parameters - it’s that simple.</p>
<p>The main problem was really to not only deal with the usual <code>onreadystatechange</code> way to use the XHR, but to enable it to all kinds of things people may do with it. That also included correctly implementing <code>EventTarget</code>, but also making sure we really catch all events. Did you know there was not only <code>load</code>, but also <code>loadstart</code>. Yes sure. But then also <code>loadend</code>. So all of that was a bit tricky, but - it works now finally.</p>
<h1 id="Using-it-as-a-cache"><a href="#Using-it-as-a-cache" class="headerlink" title="Using it as a cache"></a>Using it as a cache</h1><p>Eventually I thought, it could not only slow down requests but also speed them up.</p>
<p>No, on a serious note, what happened was that I had implemented some caching logic into a streaming engine, and then was working on XHR-shaper later. That caching module was so simple, that it was really just mapping URL’s to some sort of data (while limited to a max-total-size and purging oldest items).</p>
<p>So I thought, why could I not just cache everything that happens in the browser inside my own cache module. XHR-shaper opens me the gates of total requests manipulation. It’s really like having a proxy inside the browser.</p>
<p>Turns out yes you can do that. You can really cache <em>everything</em> that the browser gets, and deliver it to your application further times at zero-time. That is not only a good news for streaming-engines. The feature is in there and works, but it’s not yet tested in all aspects - at your own risks if you want to put this into something production-ready.</p>
<p>What is cool about the cache feature when it comes to streaming engines? Well usually with video streaming, you deal with quite a lot of data. So when you just write it into the native playback buffer of the browser i.e <code>SourceBuffer</code> of the <code>MediaSource</code> API, the browser will trim that buffer in unpredictable ways as soon as you put too much data in there. That’s why usually media-engines actually trim that buffer behind the playhead. In simple words: That’s why when you watch a long movie, it needs to rebuffer when you seek back, even if you had already loaded that part before.</p>
<p>The above problem is pretty lame, which is why media-engines can make good use of caches where they store their media data (i.e video stream segments) outside the native buffer. And then pull it out when they need to feed the buffer with that data again.</p>
<p>The cool thing now is with XHR-Shaper you can provide such a cache to any media-engine transparently, without it knowing about it (as long as it used XHRs to pull its data - it might not work with non-standard things).</p>
<h1 id="Fetch-API"><a href="#Fetch-API" class="headerlink" title="Fetch API"></a>Fetch API</h1><p>There will be a new API in browsers to make requests, it’s called <code>Fetch</code>. With that, building such a network conditioner will actually be even “simpler” - I hope.</p>
<script type="text/javascript">
    new Luminous(document.querySelector('#xhr-shaper-demo'));
</script>

<style>
    img {
        cursor: pointer;
    }

    .lum-lightbox.lum-open {
        max-width: 90%;
        margin: auto;
    }

    .lum-lightbox.lum-open img {
        border: 1px solid black;
    }
</style>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;How-to-emulate-bandwidth-conditons-in-the-browser&quot;&gt;&lt;a href=&quot;#How-to-emulate-bandwidth-conditons-in-the-browser&quot; class=&quot;headerlink&quot; t
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Visiting Association of Linux Friends in Cameroon</title>
    <link href="http://dispar.at/blog/2013/11/30/linux-friends-limbe/"/>
    <id>http://dispar.at/blog/2013/11/30/linux-friends-limbe/</id>
    <published>2013-11-30T20:38:51.000Z</published>
    <updated>2017-06-09T17:55:55.270Z</updated>
    
    <content type="html"><![CDATA[<p>In September 2012 I have visited the Association of Linux Friends in Limbe, Cameroon. A computer schooling and solar energy incubator project run by Michel Pauli. Together we have started an electronics lab with basic soldering and measurement equipment at the school, we have tought some HTML and PHP and have been mounting a solar panel on a house roof after installing solar powered lightbulbs and batteries there. This is the webpage of the fully autonomous project: <a href="http://sokolo.cronopios.org/" target="_blank" rel="external">http://sokolo.cronopios.org/</a>. They are collaborating with the activist networkers at <a href="https://www.immerda.ch" target="_blank" rel="external">https://www.immerda.ch</a>.</p>
<p>Now, <a href="https://www.flickr.com/photos/tchakabam/sets/72157638156521245/" target="_blank" rel="external">pictures will say more then words (some kind of photo story of the trip)</a>.</p>
<p><img src="http://farm8.staticflickr.com/7322/11106634175_22ab3178bc_b.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In September 2012 I have visited the Association of Linux Friends in Limbe, Cameroon. A computer schooling and solar energy incubator pro
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Travelling through central and south-east Asia</title>
    <link href="http://dispar.at/blog/2013/11/20/travel-central-asia/"/>
    <id>http://dispar.at/blog/2013/11/20/travel-central-asia/</id>
    <published>2013-11-20T20:38:51.000Z</published>
    <updated>2017-06-09T17:55:55.271Z</updated>
    
    <content type="html"><![CDATA[<p>In 2013 I ended up travelling through central Asia down to south-east. Here a few impressions from all across the long way.</p>
<p><a href="http://www.flickr.com/photos/tchakabam/10172795235/" title="DSC00513 von tchakabam bei Flickr" target="_blank" rel="external"><img src="http://farm3.staticflickr.com/2872/10172795235_26fda15151.jpg" width="500" height="332" alt="DSC00513"></a></p><br><p><a href="http://www.flickr.com/photos/tchakabam/10172926443/" title="DSC00521 von tchakabam bei Flickr" target="_blank" rel="external"><img src="http://farm8.staticflickr.com/7356/10172926443_85f23ce0c2.jpg" width="500" height="332" alt="DSC00521"></a></p><br><p><a href="http://www.flickr.com/photos/tchakabam/10172758845/" title="DSC00326 von tchakabam bei Flickr" target="_blank" rel="external"><img src="http://farm9.staticflickr.com/8266/10172758845_f53fdc0997.jpg" width="500" height="332" alt="DSC00326"></a></p><br><p><a href="http://www.flickr.com/photos/tchakabam/10172859616/" title="DSC00492 von tchakabam bei Flickr" target="_blank" rel="external"><img src="http://farm4.staticflickr.com/3688/10172859616_9d0e906e9b.jpg" width="500" height="332" alt="DSC00492"></a></p><br><p><a href="http://www.flickr.com/photos/tchakabam/10484050556/" title="DSC02692 von tchakabam bei Flickr" target="_blank" rel="external"><img src="http://farm3.staticflickr.com/2820/10484050556_3db4c18165.jpg" width="500" height="332" alt="DSC02692"></a></p><br><p><a href="http://www.flickr.com/photos/tchakabam/10484058094/" title="DSC02709 von tchakabam bei Flickr" target="_blank" rel="external"><img src="http://farm4.staticflickr.com/3769/10484058094_b3c24fb0eb.jpg" width="500" height="332" alt="DSC02709"></a></p><br><p><a href="http://www.flickr.com/photos/tchakabam/10484152503/" title="DSC02355 von tchakabam bei Flickr" target="_blank" rel="external"><img src="http://farm4.staticflickr.com/3831/10484152503_161f679ce8.jpg" width="500" height="332" alt="DSC02355"></a></p><br><p><a href="http://www.flickr.com/photos/tchakabam/10174715255/" title="DSC01263 von tchakabam bei Flickr" target="_blank" rel="external"><img src="http://farm6.staticflickr.com/5459/10174715255_75c3491b1a.jpg" width="500" height="332" alt="DSC01263"></a></p>

<p>Want to see more photos? Now you could go to my Flickr stuff <a href="http://www.flickr.com/photos/tchakabam" title="Stevan H's Flickr page" target="_blank" rel="external">here</a> </p>
<p><a href="http://www.flickr.com/photos/tchakabam" target="_blank" rel="external">http://www.flickr.com/photos/tchakabam</a>.</p>
<p>Want to talk about travelling? Drop me a line!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In 2013 I ended up travelling through central Asia down to south-east. Here a few impressions from all across the long way.&lt;/p&gt;
&lt;p&gt;&lt;a hre
    
    </summary>
    
    
  </entry>
  
</feed>
